{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPsh5huQH3hFLU9IgICnoxh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/stbalaji/stbalaji/blob/main/01RetailDemo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLa5lGS7RAhu"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = ['I love my dog', 'I love my cat', 'Good for you!', \"Do you think my dog is amazing?\"]\n",
        "tk = Tokenizer(num_words = 100)\n",
        "tk.fit_on_texts(sentences)\n",
        "wi = tk.word_index  # dictionary of Words & Encoding\n",
        "print(wi)  # Note: No 'comma' or '!' in output\n",
        "print(\"\\n\")\n",
        "seq = tk.texts_to_sequences(sentences) # Set of Sequences\n",
        "print(seq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86iRUHAORjFX",
        "outputId": "2b7ed410-de5f-433b-c569-af396a2c9194"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'my': 1, 'i': 2, 'love': 3, 'dog': 4, 'you': 5, 'cat': 6, 'good': 7, 'for': 8, 'do': 9, 'think': 10, 'is': 11, 'amazing': 12}\n",
            "\n",
            "\n",
            "[[2, 3, 1, 4], [2, 3, 1, 6], [7, 8, 5], [9, 5, 10, 1, 4, 11, 12]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try a new sentence where word is not in the vocabulary\n",
        "sentences2 = ['I love my Elephant']\n",
        "seq2 = tk.texts_to_sequences(sentences2) # Set of Sequences\n",
        "print(seq2) # [3, 4, 2, 1] ==> The value of 1 is used for Elephant as that is OOV "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuoXrsRSV2oB",
        "outputId": "ae059622-41ea-478e-c488-1fc2b85924ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3, 4, 2, 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_padded = pad_sequences(seq, padding='post', maxlen=5, truncating='post')\n",
        "print(wi)\n",
        "print(seq)\n",
        "print(seq_padded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Exs_IJE5XYi-",
        "outputId": "1a605520-224f-4376-d761-797188211255"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<OOV>': 1, 'my': 2, 'i': 3, 'love': 4, 'dog': 5, 'you': 6, 'cat': 7, 'good': 8, 'for': 9, 'do': 10, 'think': 11, 'is': 12, 'amazing': 13}\n",
            "[[3, 4, 2, 5], [3, 4, 2, 7], [8, 9, 6], [10, 6, 11, 2, 5, 12, 13]]\n",
            "[[ 3  4  2  5  0]\n",
            " [ 3  4  2  7  0]\n",
            " [ 8  9  6  0  0]\n",
            " [10  6 11  2  5]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Real-world Larger Dataset\n",
        "https://rishabhmisra.github.io/publications/#datasets\n",
        "* is_sarcastic : 1 is sarcastic\n",
        "* headline : the headline of news article\n",
        "* article_link: Supplementary information"
      ],
      "metadata": {
        "id": "HrUjcE76ZQgV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://storage.googleapis.com/tensorflow-1-public/course3/sarcasm.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksfKIOyPevVa",
        "outputId": "75d67270-fb56-4ea6-a78b-fa9b24d63fc8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-09-13 06:13:17--  https://storage.googleapis.com/tensorflow-1-public/course3/sarcasm.json\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.204.128, 64.233.188.128, 64.233.189.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.204.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5643545 (5.4M) [application/json]\n",
            "Saving to: ‘sarcasm.json’\n",
            "\n",
            "\rsarcasm.json          0%[                    ]       0  --.-KB/s               \rsarcasm.json        100%[===================>]   5.38M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2022-09-13 06:13:17 (163 MB/s) - ‘sarcasm.json’ saved [5643545/5643545]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datafile = open(\"sarcasm.json\",'r') \n",
        "data = json.load(datafile)\n",
        "print(datafile)\n",
        "\n",
        "for i in data[:5] :\n",
        "    print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n4tly8jgdlVD",
        "outputId": "bf863f17-af1a-451a-85f4-91e755589564"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<_io.TextIOWrapper name='sarcasm.json' mode='r' encoding='UTF-8'>\n",
            "{'article_link': 'https://www.huffingtonpost.com/entry/versace-black-code_us_5861fbefe4b0de3a08f600d5', 'headline': \"former versace store clerk sues over secret 'black code' for minority shoppers\", 'is_sarcastic': 0}\n",
            "{'article_link': 'https://www.huffingtonpost.com/entry/roseanne-revival-review_us_5ab3a497e4b054d118e04365', 'headline': \"the 'roseanne' revival catches up to our thorny political mood, for better and worse\", 'is_sarcastic': 0}\n",
            "{'article_link': 'https://local.theonion.com/mom-starting-to-fear-son-s-web-series-closest-thing-she-1819576697', 'headline': \"mom starting to fear son's web series closest thing she will have to grandchild\", 'is_sarcastic': 1}\n",
            "{'article_link': 'https://politics.theonion.com/boehner-just-wants-wife-to-listen-not-come-up-with-alt-1819574302', 'headline': 'boehner just wants wife to listen, not come up with alternative debt-reduction ideas', 'is_sarcastic': 1}\n",
            "{'article_link': 'https://www.huffingtonpost.com/entry/jk-rowling-wishes-snape-happy-birthday_us_569117c4e4b0cad15e64fdcb', 'headline': 'j.k. rowling wishes snape happy birthday in the most magical way', 'is_sarcastic': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentences, labels, urls = [], [], []\n",
        "\n",
        "for item in data:\n",
        "    sentences.append(item[\"headline\"])\n",
        "    labels.append(item[\"is_sarcastic\"])\n",
        "    urls.append(item[\"article_link\"])\n",
        "\n",
        "print(len(labels))"
      ],
      "metadata": {
        "id": "M7OIPrHnfdyB",
        "outputId": "a1544912-d396-47f5-87d8-9aa1a67776b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "26709\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Processing the Headlines...Padded Sequences"
      ],
      "metadata": {
        "id": "9DWyxJELgQmt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer(oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "\n",
        "wi = tokenizer.word_index\n",
        "print(\"\\nWord Index len\", len(wi))  #wi is dictionary\n",
        "print(\"Word Indexes\", type(wi))\n",
        "seq = tokenizer.texts_to_sequences(sentences)\n",
        "# seq[0:3]\n",
        "padded_seq = pad_sequences(seq, padding='post')\n"
      ],
      "metadata": {
        "id": "GmGUtIQjgW3k",
        "outputId": "e74a4cb4-a0b5-4bb6-9766-e874b58e5b08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Word Index len 29657\n",
            "Word Indexes <class 'dict'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "ind = random.randint(0, len(seq))\n",
        "print(\"Sample: \", sentences[ind])\n",
        "print(\"Sample: \", padded_seq[ind])\n",
        "print(\"shape: \", padded_seq.shape)\n"
      ],
      "metadata": {
        "id": "FcBJbAlzhooy",
        "outputId": "72824f49-38c0-4ac4-feab-cb8f1045f210",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample:  shaken attorney general resigns after learning what murder is\n",
            "Sample:  [4228 1657  896 1955   21 1085   33  779   11    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "    0    0    0    0    0    0    0    0    0    0    0    0]\n",
            "Sample:  (26709, 40)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "eeAADCnQcm9J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: the text to sequences called can take any set of sentences,\n",
        "so it can encode them based on the **word set **that it\n",
        "learned from the one that was passed into fit on texts"
      ],
      "metadata": {
        "id": "w9w-sdzIUVJ4"
      }
    }
  ]
}